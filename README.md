# ğŸ“° Text Summarization with T5 & CNN/DailyMail

Ce projet implÃ©mente un modÃ¨le de **Deep Learning** pour le rÃ©sumÃ© automatique de textes journalistiques. Il utilise l'architecture **T5 (Text-To-Text Transfer Transformer)** fine-tunÃ©e sur le dataset **CNN/DailyMail**.

## ğŸš€ FonctionnalitÃ©s
- **Fine-tuning** du modÃ¨le `t5-small` sur des articles de presse.
- **PrÃ©traitement** des donnÃ©es (Tokenization, Nettoyage).
- **Visualisation** des donnÃ©es (WordClouds, distribution des longueurs).
- **Ã‰valuation** avec la mÃ©trique **ROUGE** (Recall-Oriented Understudy for Gisting Evaluation).
- **Interface** de visualisation des courbes de perte (Training vs Validation).

## ğŸ› ï¸ Technologies
* **Python 3.10+**
* **Hugging Face Transformers** (T5, Seq2SeqTrainer)
* **PyTorch**
* **Pandas / Matplotlib / Seaborn**

## ğŸ“Š RÃ©sultats
Le modÃ¨le a Ã©tÃ© entraÃ®nÃ© sur GPU (T4 x2) avec les hyperparamÃ¨tres suivants :
- **Epochs:** 3
- **Batch Size:** 32
- **Optimizer:** AdamW

## ğŸ“¦ Installation
1. Clonez le dÃ©pÃ´t :
```bash
git clone [https://github.com/Safae26/text-summarization.git](https://github.com/Safae26/text-summarization.git)
