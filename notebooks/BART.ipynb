{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "a1e443ca0a0d46509fa2c916ae6c5a97",
      "efb1859c395843c5840b4b512d7e55a3",
      "f95dc8b1507f4a30ba644b5a53e9e091",
      "575dda48325841c187ba0dd7d7839beb",
      "122ae403c5e944189c729f973a9dcc22",
      "4e2c2bb5d89a4ad79892d6f4b9b53851",
      "11e8e3b41fd942bca5faaf480738da38",
      "fd52aa5d17044e6992e9bf006a58d8b2",
      "35ca5d8a0d5b408aa812326137e12a32",
      "2f85682a8b2f44bfac7c5b40b15bb81f",
      "42793f4de3f747c28e289025e0f079ce",
      "45841de2d08944f8aaa852276be00488",
      "f40a6165032840b19e4307119bc0c80f",
      "625db25d7ead4cb5aa6d79c48e273c7c",
      "9a50ee78e0104661bbacb802e3e15ca1",
      "4945c447d6ab4b6e84afb06aeadf1507",
      "46357d30eb9840e49591b0eb47555877",
      "0b232fb5821e4d14b9275f7300312b06",
      "96c40962faf646d792141fa82e80f7fb",
      "bc545b17c44940b0bb0c7c331ccef137",
      "41a46d1bd3414c91b0f325b4d4260efe",
      "d370cab01cf74b98804a8d66d40d8130",
      "2de3aec09ab34ce0936a06bfa797aa9c",
      "893307098b6a43bea28875e434767890",
      "e8777b3c45294fd3bb1a5c67aae16446",
      "2b78f799ecc6424ebee0765bbd5e47a4",
      "bc1ea7f3e266461baaa2934ae6124ce3",
      "3b317f5106d04ad9b41105f0a07c2867",
      "47c13bd785dc492abe86ec52a446dc64",
      "acc43b38b79749fbb124a069e04ed1ac",
      "aff5a680e88344e1bacb6c72f0b13b6c",
      "72984aca7e274414a0564526f84eb177",
      "ca4156ff64b84e7db64ad7c37ae3da6f",
      "dfeaaf76a0aa423b9a22c3967d9303a4",
      "05954b67d6de43f89a04e8d8f786aafd",
      "256a158bd3044cfe80ce4c3326156659",
      "6489a741df2742249850cdbe440efcc7",
      "d81e65abd8a245e3a795e8d3e453a6d6",
      "e05df7b1d17b417ea6f001ab9505c738",
      "dccd81702e7b40e4a8d869c362c80bca",
      "56b685bab9cf43d8a46966b0058450c9",
      "f431c461e1e9448d92d79636a4e43740",
      "1f4a1616d2b04e6d850b996a84fbde42",
      "a1bb3b40f91d4a69a0bb3dc6b115eeac",
      "6cdcbb3c3bde4ac1a1bbb45b3559ea2c",
      "07da3d0fdcbe40f9b6fe4df40291d32a",
      "83e2d19c48774193ad3c52a29878506a",
      "0f38b2f5ea09465abbb8e5de1b7b8fa5",
      "3beae08e4545485e9cfff999c10f67b3",
      "8406f77db6664172bf1a94edccc58a60",
      "55d113744b0b4ecda4acf7a6345a0f9a",
      "0cefc905db104979bae5a4261205f86e",
      "7c07b6163abd4fea93d6395349566243",
      "a7f440ba4a22446c88ab845ae5522887",
      "9684651df8ec45ef8a19b41750c5529e",
      "bb765efd20ef4354a781ca0da71b3691",
      "48a10e35e2ed4018a59d07948d59d047",
      "a4a95aa244234d8886b64761cea47812",
      "0a2f65f380c44ec1ae70b26878f460f3",
      "f949ae8152a64b2dbf122604b37339be",
      "9534b08c3d9e49c098074f2c17a4b0a7",
      "aa5b369b2a164059b4ef7953b53fa73b",
      "0b88c99cf22440d0bf22eac0ffff0f4c",
      "85d4ceaf86514610bac0f1d0eaf92e29",
      "6bd8f19a48db4b3c8b595d25a9535e7a",
      "5eacd6f63f064e47bfb4065e71af5be7",
      "fcf2ef0ccfda4c43a9970c5e2dd06846",
      "4b69922593ed4cfda559940687913f56",
      "f2a0eb35a15c488ab7a3de8603073bf3",
      "c88a445830a7418daba50cfd5c7c62ac",
      "90275471f1c14f1d9d4b4643f418e398",
      "9acdd3dcbc8c4f628c7888641b0302be",
      "b95de0a0c792453c84b3fae2388ac74b",
      "8db422c9ba4d4856b9170ffb1b9759e4",
      "35bcb136a8e04bfab07dbcd728306f59",
      "fd32d1f1d6ad4a77970ff486df48911a",
      "94c5069392f64a6482dd225f48cfba09",
      "8142104dcbda446c8dcccf13e227d9bd",
      "293986579da54e6c867fa29191650211",
      "985494b88c3643989b7e710366010852",
      "3721524021734144ab2884e6c615fe0a",
      "663a75d4b27c4971ace28a8616660924",
      "bc2ca5e2b8f64603b760aae93c29baaa",
      "95b0570a5db047daa492e7b8d2b8d426",
      "c6a9a7d43c1b4eb29c54979f00bd8cad",
      "4c0d3cd8197148d39c85ba0e9e848801",
      "f60fd2d185bf4de0a6cd5af007a95cca",
      "b1b59c4ca3834beaa779a6ea19775173",
      "72ced8a79b1241e8ac28539595bc43c7",
      "e494bd06bb4243a193c527fa5306b5b2",
      "6767710cd57743f88fbb6a3daf8c0128",
      "7cda4fe4d56e48599456408b6f916a6a",
      "89abf697b74e42c7809d443d8b207149",
      "35df3e604e1643fe8ee473bf246be85f",
      "206d0104cf2c4dbeb8c4ef683f054802",
      "7114e4543c08430e8652bf3cbad22a05",
      "b0c4773187084096be6f25bed901062e",
      "40a707a92a0846bea3c51eea727b31b5",
      "d54ff1153d4c4ab9821f3e8899fd2092",
      "b959bd790a874ef58ef24d2e0d84781b",
      "ebde5c9db2984ed8bff3a60c10b45be9",
      "a73591a6200548d697ba5e6e7179df09",
      "386d8282fbfd440bbdd3815bf9d9863e",
      "2d66ba0354384a62a8970f0e778c9ec8",
      "b6abc192c188477eb9627d749675f1f7",
      "0e368879f41a4eec834c7ccbef399ae9",
      "9327a0ba2ca54fbfa4aca3c905075c53",
      "2deb09051d4f4339b4b7111162c89d41",
      "58d6b51d1f45428c840cf1e81246deef",
      "36f2e8b791384d7596d985ee46889990",
      "e243cb1949ae4c9690f5411abcdb16a0",
      "74aff8d08db547c282619b20cd884bba",
      "d5070324fde547e4abb4f50bb8c6f774",
      "a2b6da5f934d41e4bef1d0cb8b7567f4",
      "2b7e0804672340668d35b4115d32540a",
      "468690dc4e0c4f8dbdb49e174ec0e656",
      "ebea2d12a5934c78a0242399539381ca",
      "dbb5a5a462954198aba6a522493cbd0d",
      "53a07bfb71d84c3c9086e2a955e23dd7",
      "6c9efa73869d457a9af693f8d1828c9d",
      "6a5a4dafd6e647e685e9980b9895491e",
      "d5ac7c68bc9143388d4f16b8ae0d532c",
      "fda1ac4cf5c5494eb42fb280a082b728",
      "320735dae4934d2ab68f24eaaadae902",
      "1e480fc5ca054cedb311adbecbd68c49",
      "c77be76183794e379f0037c8c1e812a8",
      "4473d1bc7d5640b98493ad9209cdac61",
      "4286b2334dcb4a02881f6d71204e6c6b",
      "308cea191ea94ccc98224d495eeaa013",
      "f650f833664b4362b1a533973e5257a7",
      "0b9a34f0ecbb45b8b96c76f9afcc7f38",
      "1ca22e534b7744b692bfe9b337b6444e",
      "1ccbc5a3638941c4815b61e96b92c487",
      "7c9d8a4ec5e34b83ad207296cc05b007",
      "a10b7f35bc3b42e1b9c9c8ffe60657f0",
      "e1b63600b68d41108d441f2b0c406c2d",
      "b314e69715be46d79a46fbcd6f0cee75",
      "6956f3239285448bb95d7b3a07c6af1c",
      "8b6deec57d4c46e4a85f07fc025f822b",
      "7f7cd02cccbf4faaa92fe16caecb44e7",
      "d459a917f5c542f98175a68b9fbceff6",
      "c3b4a3dccda04d218f14012fc536e25f",
      "c5b10cd4dcec4ff489b4a44213fa98b3",
      "72fc831751a84ca785613640eb8f6b79",
      "a794c1cb037e4dcf8f31732e7f167e48",
      "77fb426d60fa46b7ab68429b442875ef",
      "b029409b3b7d4fcd99ea0a218ddccba7",
      "e9b2cb05fa9d432ab083e7ceaaac0546",
      "25a3db362b6d4256aac31e791744b303",
      "88b9ebbae71342958ab3c434c1b7f44b",
      "3c7c5dabffe347998d1029a9afc22266",
      "093053cb6c2940289494756320b6211b",
      "3fbf2ee0a9c94bda8a09d4bbf85f2ad3",
      "b90637b70a9542858af60e4bd83e87ea",
      "1d1f37aa7e7d4832ab0107bd977d61fd",
      "456548630cf742e0ad8f53e52b0bd5c4",
      "0854defadc9a4af1850e935e994155ff",
      "823ebdb878d948af8a980d46bfb0a2e9",
      "d19f444997f94a2cbdec19be6298b92a",
      "280203435ae94f07b6599fe22a6285d5",
      "42beb8b9c0c64ea0b58fa35602000d33",
      "c07e11f45c424aa09ac50c50d81d0797",
      "0df0f95d54f5400098d61d0b61f40265",
      "6e1f621fd3714a0e9781195c69811169",
      "19b02ea2b86c4b12b3c32874d38219c6",
      "d3f400893d0e435b84f9a55c11c3f5bf",
      "6a2ee050e4374f999348afe19b49a406",
      "ef5a8580d8d947fdafbf1bd82c16bb49",
      "075ba4d3a29c4e44b94d11db59d8fbd9",
      "3ea0be35c6494a06b811360cd26ae47a",
      "05779bf575994485a137f548899cb49f",
      "80f2ab59c1bd458aa4c3effdaceada71",
      "099a8c9075ac4cfe90dbac892b6be9a4",
      "4729a17f15f849eb830c147758bc9244",
      "f97888e99e574b39b9ea6cbc1fc52526",
      "6d6faa14ae3d4ff7bbaffce4c762f76c"
     ]
    },
    "id": "TqbaWDc2gdWP",
    "outputId": "724522e7-ba7d-4620-d82c-b81fb1aa8ec2"
   },
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# FINE-TUNING BART SUR CNN/DAILYMAIL (5000 exemples)\n",
    "# ==============================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FINE-TUNING BART (140M) - COMME L'ARTICLE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ==============================================\n",
    "# 1. INSTALLATIONS\n",
    "# ==============================================\n",
    "\n",
    "!pip install transformers datasets accelerate rouge-score nltk -q\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, Trainer, TrainingArguments\n",
    "import gc\n",
    "import os\n",
    "\n",
    "# Nettoyage m√©moire\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
    "\n",
    "print(\"‚úÖ Biblioth√®ques install√©es\")\n",
    "\n",
    "# ==============================================\n",
    "# 2. DATASET (5000 train, 1000 val, 1000 test)\n",
    "# ==============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä CHARGEMENT DU DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
    "\n",
    "# Split comme dans l'article\n",
    "train_dataset = dataset[\"train\"].select(range(5000))      # 5000 training\n",
    "val_dataset = dataset[\"validation\"].select(range(1000))   # 1000 validation\n",
    "test_dataset = dataset[\"test\"].select(range(1000))        # 1000 test\n",
    "\n",
    "print(f\"‚úÖ Dataset pr√™t:\")\n",
    "print(f\"  Training:   {len(train_dataset)} exemples\")\n",
    "print(f\"  Validation: {len(val_dataset)} exemples\")\n",
    "print(f\"  Test:       {len(test_dataset)} exemples\")\n",
    "\n",
    "# ==============================================\n",
    "# 3. TOKENISATION\n",
    "# ==============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üî§ TOKENISATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    \"\"\"Pr√©traitement comme dans l'article\"\"\"\n",
    "    # Input: articles\n",
    "    inputs = tokenizer(\n",
    "        examples[\"article\"],\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=None\n",
    "    )\n",
    "\n",
    "    # Labels: summaries\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            examples[\"highlights\"],\n",
    "            max_length=128,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=None\n",
    "        )\n",
    "\n",
    "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "print(\"Tokenisation en cours...\")\n",
    "tokenized_train = train_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    batch_size=8,\n",
    "    remove_columns=train_dataset.column_names,\n",
    "    desc=\"Tokenisation training\"\n",
    ")\n",
    "\n",
    "tokenized_val = val_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    batch_size=8,\n",
    "    remove_columns=val_dataset.column_names,\n",
    "    desc=\"Tokenisation validation\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Tokenisation termin√©e\")\n",
    "\n",
    "# ==============================================\n",
    "# 4. MOD√àLE BART (140M param√®tres)\n",
    "# ==============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üß† CHARGEMENT DE BART-BASE (140M)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained(\n",
    "    \"facebook/bart-base\",\n",
    "    use_cache=False  # Important pour gradient checkpointing\n",
    ")\n",
    "\n",
    "# Activer gradient checkpointing pour √©conomiser m√©moire\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"‚úÖ BART-base charg√©\")\n",
    "print(f\"üìä Param√®tres: {total_params/1e6:.1f}M\")\n",
    "print(f\"üìä Device: {model.device}\")\n",
    "\n",
    "# ==============================================\n",
    "# 5. CONFIGURATION DU FINE-TUNING\n",
    "# ==============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚öôÔ∏è  CONFIGURATION DU FINE-TUNING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bart-finetuned-5000\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=5,  # Comme dans l'article\n",
    "    per_device_train_batch_size=2,  # Petit pour √©viter OOM\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=8,  # Batch effectif = 16\n",
    "    learning_rate=1e-5,  # Faible comme dans l'article\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    fp16=True,  # Mixed precision\n",
    "    report_to=\"none\",\n",
    "    gradient_checkpointing=True,\n",
    "    dataloader_pin_memory=False,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Configuration d√©finie:\")\n",
    "print(f\"  ‚Ä¢ Epochs: 5 (comme l'article)\")\n",
    "print(f\"  ‚Ä¢ Batch size: 2\")\n",
    "print(f\"  ‚Ä¢ Learning rate: 1e-5\")\n",
    "print(f\"  ‚Ä¢ Gradient checkpointing: ACTIV√â\")\n",
    "\n",
    "# ==============================================\n",
    "# 6. FINE-TUNING\n",
    "# ==============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üî• D√âBUT DU FINE-TUNING\")\n",
    "print(\"=\"*60)\n",
    "print(\"‚ö†Ô∏è  Cette √©tape prend 2-3 heures\")\n",
    "print(\"    Si OOM error, r√©duis batch_size √† 1\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "try:\n",
    "    train_result = trainer.train()\n",
    "    print(f\"\\n‚úÖ FINE-TUNING R√âUSSI !\")\n",
    "    print(f\"‚è±Ô∏è  Temps: {train_result.metrics['train_runtime']/60:.1f} min\")\n",
    "    print(f\"üìâ Training loss: {train_result.metrics['train_loss']:.3f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå ERREUR: {e}\")\n",
    "    print(\"\\nüîÑ Tentative avec batch_size=1...\")\n",
    "\n",
    "    # R√©essayer avec batch size plus petit\n",
    "    training_args.per_device_train_batch_size = 1\n",
    "    training_args.per_device_eval_batch_size = 1\n",
    "    training_args.gradient_accumulation_steps = 16\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_val,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    train_result = trainer.train()\n",
    "    print(f\"\\n‚úÖ FINE-TUNING R√âUSSI avec batch_size=1\")\n",
    "\n",
    "# ==============================================\n",
    "# 7. SAUVEGARDE DU MOD√àLE FINE-TUN√â\n",
    "# ==============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üíæ SAUVEGARDE DU MOD√àLE FINE-TUN√â\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_save_path = \"./bart_finetuned_5000\"\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "print(f\"‚úÖ Mod√®le fine-tun√© sauvegard√© dans: {model_save_path}\")\n",
    "\n",
    "# ==============================================\n",
    "# 8. √âVALUATION SUR TEST SET (1000 exemples)\n",
    "# ==============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä √âVALUATION ROUGE SUR TEST SET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "!pip install rouge-score -q\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL', 'rougeLsum'], use_stemmer=True)\n",
    "\n",
    "# Fonction de g√©n√©ration\n",
    "def generate_summary(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        summary_ids = model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            max_length=100,\n",
    "            min_length=30,\n",
    "            length_penalty=2.0,\n",
    "            num_beams=4,\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# √âvaluation sur 1000 exemples\n",
    "print(f\"√âvaluation sur 1000 exemples du test set...\")\n",
    "\n",
    "rouge1_scores = []\n",
    "rouge2_scores = []\n",
    "rougeL_scores = []\n",
    "rougeLsum_scores = []\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(1000):\n",
    "    article = test_dataset[i][\"article\"]\n",
    "    reference = test_dataset[i][\"highlights\"]\n",
    "\n",
    "    generated = generate_summary(article)\n",
    "    scores = scorer.score(reference, generated)\n",
    "\n",
    "    rouge1_scores.append(scores['rouge1'].fmeasure)\n",
    "    rouge2_scores.append(scores['rouge2'].fmeasure)\n",
    "    rougeL_scores.append(scores['rougeL'].fmeasure)\n",
    "    rougeLsum_scores.append(scores['rougeLsum'].fmeasure)\n",
    "\n",
    "    if (i + 1) % 100 == 0:\n",
    "        progress = (i + 1) / 1000 * 100\n",
    "        current_rouge1 = np.mean(rouge1_scores) * 100\n",
    "        print(f\"  {i+1}/1000 ({progress:.0f}%) - ROUGE-1: {current_rouge1:.1f}%\")\n",
    "\n",
    "eval_time = time.time() - start_time\n",
    "\n",
    "# ==============================================\n",
    "# 9. R√âSULTATS ROUGE (comme l'article)\n",
    "# ==============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìà R√âSULTATS ROUGE - BART FINE-TUN√â\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "rouge1 = np.mean(rouge1_scores) * 100\n",
    "rouge2 = np.mean(rouge2_scores) * 100\n",
    "rougeL = np.mean(rougeL_scores) * 100\n",
    "rougeLsum = np.mean(rougeLsum_scores) * 100\n",
    "\n",
    "print(f\"\\nüéØ TES R√âSULTATS (1000 exemples):\")\n",
    "print(f\"  ROUGE-1:    {rouge1:.2f}%\")\n",
    "print(f\"  ROUGE-2:    {rouge2:.2f}%\")\n",
    "print(f\"  ROUGE-L:    {rougeL:.2f}%\")\n",
    "print(f\"  ROUGE-Lsum: {rougeLsum:.2f}%\")\n",
    "\n",
    "print(f\"\\nüìä STATISTIQUES:\")\n",
    "print(f\"  √âcart-type ROUGE-1: {np.std(rouge1_scores)*100:.2f}%\")\n",
    "print(f\"  Temps d'√©valuation: {eval_time/60:.1f} min\")\n",
    "\n",
    "# ==============================================\n",
    "# 10. COMPARAISON AVEC L'ARTICLE\n",
    "# ==============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä COMPARAISON AVEC L'ARTICLE (Table 3)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n{'Mod√®le':<25} {'ROUGE-1':<10} {'ROUGE-2':<10} {'ROUGE-L':<10} {'ROUGE-Lsum':<10}\")\n",
    "print(\"-\" * 65)\n",
    "print(f\"{'Article BART':<25} {27.61:<10.2f} {18.37:<10.2f} {28.52:<10.2f} {25.84:<10.2f}\")\n",
    "print(f\"{'Ton BART (5000 ex)':<25} {rouge1:<10.2f} {rouge2:<10.2f} {rougeL:<10.2f} {rougeLsum:<10.2f}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "difference_rouge1 = rouge1 - 27.61\n",
    "print(f\"\\nüìà Diff√©rence ROUGE-1: {difference_rouge1:+.2f}%\")\n",
    "\n",
    "if difference_rouge1 > 0:\n",
    "    print(\"‚úÖ Ton mod√®le performe MIEUX que l'article !\")\n",
    "elif difference_rouge1 > -5:\n",
    "    print(\"üëç Performance proche de l'article (normal avec moins de donn√©es)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Performance inf√©rieure (normal: 5000 vs 287K exemples dans l'article)\")\n",
    "\n",
    "# ==============================================\n",
    "# 11. SAUVEGARDE DES R√âSULTATS\n",
    "# ==============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üíæ SAUVEGARDE FINALE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Cr√©er dossier r√©sultats\n",
    "results_dir = \"./bart_finetuned_results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Sauvegarder les r√©sultats\n",
    "results = {\n",
    "    \"model\": \"BART-base (140M) fine-tuned\",\n",
    "    \"training\": {\n",
    "        \"examples\": 5000,\n",
    "        \"validation\": 1000,\n",
    "        \"epochs\": 5,\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"batch_size\": 2\n",
    "    },\n",
    "    \"evaluation\": {\n",
    "        \"test_examples\": 1000,\n",
    "        \"rouge1\": float(rouge1),\n",
    "        \"rouge2\": float(rouge2),\n",
    "        \"rougeL\": float(rougeL),\n",
    "        \"rougeLsum\": float(rougeLsum),\n",
    "        \"std_rouge1\": float(np.std(rouge1_scores) * 100)\n",
    "    },\n",
    "    \"comparison_with_article\": {\n",
    "        \"article_rouge1\": 27.61,\n",
    "        \"article_rouge2\": 18.37,\n",
    "        \"article_rougeL\": 28.52,\n",
    "        \"article_rougeLsum\": 25.84,\n",
    "        \"difference_rouge1\": float(difference_rouge1)\n",
    "    },\n",
    "    \"date\": datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "with open(os.path.join(results_dir, \"results.json\"), \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ R√©sultats sauvegard√©s dans: {results_dir}/results.json\")\n",
    "\n",
    "# ==============================================\n",
    "# 12. T√âL√âCHARGEMENT\n",
    "# ==============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üì¶ PR√âPARATION DU T√âL√âCHARGEMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import shutil\n",
    "\n",
    "# Cr√©er ZIP avec mod√®le + r√©sultats\n",
    "final_dir = \"./bart_project_final\"\n",
    "os.makedirs(final_dir, exist_ok=True)\n",
    "\n",
    "# Copier mod√®le\n",
    "shutil.copytree(model_save_path, os.path.join(final_dir, \"model\"), dirs_exist_ok=True)\n",
    "# Copier r√©sultats\n",
    "shutil.copy(os.path.join(results_dir, \"results.json\"), os.path.join(final_dir, \"results.json\"))\n",
    "\n",
    "# Cr√©er ZIP\n",
    "zip_name = \"bart_finetuned_project\"\n",
    "shutil.make_archive(zip_name, 'zip', final_dir)\n",
    "\n",
    "# T√©l√©charger\n",
    "from google.colab import files\n",
    "files.download(f\"{zip_name}.zip\")\n",
    "\n",
    "print(f\"\\n‚úÖ PROJET TERMIN√â !\")\n",
    "print(f\"üì¶ Fichier: {zip_name}.zip\")\n",
    "print(f\"üìä ROUGE-1: {rouge1:.2f}%\")\n",
    "print(f\"üìà Comparaison article: {difference_rouge1:+.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6bk_JWIjjN8V"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
