{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "ce7b52ed87f64032a274d0e0185303be",
      "d4bfb97bef5442fbb59274f779642604",
      "7528bebf96424399ba535750926f7432",
      "53aa68b3306c47e7afc3c1ab16e90974",
      "1dca08df91b64edf9226b9bc3908e379",
      "5ed9c7925b514765b9ed76ccae63467a",
      "78755253b1c2492c873a603ab3142942",
      "1b90858da9f2424bbdd57cca438536b7",
      "84b79d0054e649539b281e4d7fc60f90",
      "bd80a1d3587f434eba3ca84fb655615c",
      "3a15918188c3486b8ed2d03f48a57c1a",
      "8112318d259d457cb32a4b7be1f5772b",
      "ff7c51f7a0474823a37bb2c68db6300d",
      "2d77685564824d0e9176057474178ab6",
      "5b9178b3873849f8b69d05af21ddbf20",
      "6e0a2f19aacd4696adf727198dc83240",
      "272e19d13a4c4e6e8faf0709180432f2",
      "2afa66ca4ee248b396df448c02d01723",
      "0e28c9ed1a564acaaf45c56766672db0",
      "53f4bab226a44de489820f37c10f1001",
      "33630ff89d494299b5af9ea6df31ed44",
      "0f0ba9a77339497d8fc968097e799d1f"
     ]
    },
    "id": "S5dbweZzSFso",
    "outputId": "3ec79e55-53a3-49d0-83a4-09119e179b47"
   },
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# FINE-TUNING PEGASUS SUR CNN/DAILYMAIL (5000 exemples)\n",
    "# ==============================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FINE-TUNING PEGASUS - COMME L'ARTICLE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ==============================================\n",
    "# 1. INSTALLATIONS\n",
    "# ==============================================\n",
    "\n",
    "!pip install transformers datasets accelerate rouge-score sentencepiece -q\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import PegasusTokenizer, PegasusForConditionalGeneration, Trainer, TrainingArguments\n",
    "import gc\n",
    "import os\n",
    "\n",
    "# Nettoyage m√©moire\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "print(\"‚úÖ Biblioth√®ques install√©es\")\n",
    "\n",
    "# ==============================================\n",
    "# 2. DATASET (5000 train, 1000 val, 1000 test)\n",
    "# ==============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä CHARGEMENT DU DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
    "\n",
    "# Split comme dans l'article\n",
    "train_dataset = dataset[\"train\"].select(range(5000))      # 5000 training\n",
    "val_dataset = dataset[\"validation\"].select(range(1000))   # 1000 validation\n",
    "test_dataset = dataset[\"test\"].select(range(1000))        # 1000 test\n",
    "\n",
    "print(f\"‚úÖ Dataset pr√™t:\")\n",
    "print(f\"  Training:   {len(train_dataset)} exemples\")\n",
    "print(f\"  Validation: {len(val_dataset)} exemples\")\n",
    "print(f\"  Test:       {len(test_dataset)} exemples\")\n",
    "\n",
    "# ==============================================\n",
    "# 3. TOKENISATION PEGASUS\n",
    "# ==============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üî§ TOKENISATION PEGASUS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Charger PEGASUS-base (pas large)\n",
    "tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-cnn_dailymail\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    \"\"\"Pr√©traitement pour PEGASUS\"\"\"\n",
    "    # Input: articles\n",
    "    inputs = tokenizer(\n",
    "        examples[\"article\"],\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=None\n",
    "    )\n",
    "\n",
    "    # Labels: summaries\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            examples[\"highlights\"],\n",
    "            max_length=128,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=None\n",
    "        )\n",
    "\n",
    "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "print(\"Tokenisation en cours...\")\n",
    "tokenized_train = train_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    batch_size=8,\n",
    "    remove_columns=train_dataset.column_names,\n",
    "    desc=\"Tokenisation training\"\n",
    ")\n",
    "\n",
    "tokenized_val = val_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    batch_size=8,\n",
    "    remove_columns=val_dataset.column_names,\n",
    "    desc=\"Tokenisation validation\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Tokenisation termin√©e\")\n",
    "\n",
    "# ==============================================\n",
    "# 4. MOD√àLE PEGASUS (base, 175M param√®tres)\n",
    "# ==============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üß† CHARGEMENT DE PEGASUS-BASE (175M)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Charger PEGASUS pr√©-entra√Æn√© sur CNN/DailyMail\n",
    "model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-cnn_dailymail\")\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"‚úÖ PEGASUS-base charg√©\")\n",
    "print(f\"üìä Param√®tres: {total_params/1e6:.1f}M (comme l'article)\")\n",
    "print(f\"üìä Device: {model.device}\")\n",
    "\n",
    "# ==============================================\n",
    "# 5. CONFIGURATION DU FINE-TUNING\n",
    "# ==============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚öôÔ∏è  CONFIGURATION DU FINE-TUNING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./pegasus-finetuned-5000\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=5,  # Comme dans l'article\n",
    "    per_device_train_batch_size=4,  # PEGASUS est plus l√©ger que BART\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=4,  # Batch effectif = 16\n",
    "    learning_rate=1e-5,  # Faible comme dans l'article\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs-pegasus\",\n",
    "    logging_steps=100,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    "    dataloader_pin_memory=False,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Configuration d√©finie:\")\n",
    "print(f\"  ‚Ä¢ Epochs: 5 (comme l'article)\")\n",
    "print(f\"  ‚Ä¢ Batch size: 4\")\n",
    "print(f\"  ‚Ä¢ Learning rate: 1e-5\")\n",
    "\n",
    "# ==============================================\n",
    "# 6. FINE-TUNING PEGASUS\n",
    "# ==============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üî• D√âBUT DU FINE-TUNING PEGASUS\")\n",
    "print(\"=\"*60)\n",
    "print(\"‚ö†Ô∏è  Cette √©tape prend 1-2 heures\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "try:\n",
    "    train_result = trainer.train()\n",
    "    print(f\"\\n‚úÖ FINE-TUNING R√âUSSI !\")\n",
    "    print(f\"‚è±Ô∏è  Temps: {train_result.metrics['train_runtime']/60:.1f} min\")\n",
    "    print(f\"üìâ Training loss: {train_result.metrics['train_loss']:.3f}\")\n",
    "\n",
    "except RuntimeError as e:\n",
    "    if \"out of memory\" in str(e).lower():\n",
    "        print(f\"\\n‚ö†Ô∏è  M√©moire insuffisante, ajustement des param√®tres...\")\n",
    "        print(\"üîÑ Tentative avec batch_size=1 et gradient checkpointing...\")\n",
    "\n",
    "        training_args.per_device_train_batch_size = 1\n",
    "        training_args.per_device_eval_batch_size = 1\n",
    "        training_args.gradient_accumulation_steps = 16\n",
    "        training_args.gradient_checkpointing = True\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=tokenized_train,\n",
    "            eval_dataset=tokenized_val,\n",
    "            tokenizer=tokenizer,\n",
    "        )\n",
    "\n",
    "        train_result = trainer.train()\n",
    "        print(f\"\\n‚úÖ FINE-TUNING R√âUSSI avec batch_size=1 et gradient checkpointing\")\n",
    "    else:\n",
    "        raise e\n",
    "\n",
    "# ==============================================\n",
    "# 7. SAUVEGARDE DU MOD√àLE FINE-TUN√â\n",
    "# ==============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üíæ SAUVEGARDE DU MOD√àLE PEGASUS FINE-TUN√â\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_save_path = \"./pegasus_finetuned_5000\"\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "print(f\"‚úÖ Mod√®le PEGASUS fine-tun√© sauvegard√© dans: {model_save_path}\")\n",
    "\n",
    "# ==============================================\n",
    "# 8. √âVALUATION SUR TEST SET (1000 exemples) - CORRIG√â\n",
    "# ==============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä √âVALUATION ROUGE SUR TEST SET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "!pip install rouge-score -q\n",
    "from rouge_score import rouge_scorer\n",
    "import torch\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL', 'rougeLsum'], use_stemmer=True)\n",
    "\n",
    "# Fonction de g√©n√©ration CORRIG√âE\n",
    "def generate_summary_pegasus(text, model, tokenizer, device):\n",
    "    \"\"\"G√©n√®re un r√©sum√© avec PEGASUS fine-tun√©\"\"\"\n",
    "    # Mode √©valuation\n",
    "    model.eval()\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding=True\n",
    "    )\n",
    "\n",
    "    # D√©placer sur le bon device\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        summary_ids = model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_length=100,\n",
    "            min_length=30,\n",
    "            length_penalty=0.8,\n",
    "            num_beams=4,\n",
    "            early_stopping=True,\n",
    "            no_repeat_ngram_size=3\n",
    "        )\n",
    "\n",
    "    # Nettoyage m√©moire\n",
    "    del inputs\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# √âvaluation CORRIG√âE\n",
    "print(f\"√âvaluation sur 1000 exemples du test set...\")\n",
    "\n",
    "pegasus_rouge1 = []\n",
    "pegasus_rouge2 = []\n",
    "pegasus_rougeL = []\n",
    "pegasus_rougeLsum = []\n",
    "\n",
    "# D√©terminer le device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    for i in range(1000):\n",
    "        article = test_dataset[i][\"article\"]\n",
    "        reference = test_dataset[i][\"highlights\"]\n",
    "\n",
    "        # G√©n√©rer avec gestion de m√©moire\n",
    "        generated = generate_summary_pegasus(article, model, tokenizer, device)\n",
    "\n",
    "        # Calculer scores ROUGE\n",
    "        scores = scorer.score(reference, generated)\n",
    "\n",
    "        pegasus_rouge1.append(scores['rouge1'].fmeasure)\n",
    "        pegasus_rouge2.append(scores['rouge2'].fmeasure)\n",
    "        pegasus_rougeL.append(scores['rougeL'].fmeasure)\n",
    "        pegasus_rougeLsum.append(scores['rougeLsum'].fmeasure)\n",
    "\n",
    "        # Nettoyer m√©moire p√©riodiquement\n",
    "        if (i + 1) % 50 == 0 and torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        # Progression\n",
    "        if (i + 1) % 100 == 0:\n",
    "            progress = (i + 1) / 1000 * 100\n",
    "            current_rouge1 = np.mean(pegasus_rouge1) * 100\n",
    "            print(f\"  {i+1}/1000 ({progress:.0f}%) - ROUGE-1: {current_rouge1:.1f}%\")\n",
    "\n",
    "except RuntimeError as e:\n",
    "    if \"out of memory\" in str(e).lower():\n",
    "        print(f\"\\n‚ö†Ô∏è  M√©moire GPU satur√©e √† l'it√©ration {i+1}\")\n",
    "        print(f\"üîÑ √âvaluation partielle termin√©e: {len(pegasus_rouge1)} exemples\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå Erreur lors de l'√©valuation: {e}\")\n",
    "        raise e\n",
    "\n",
    "finally:\n",
    "    # Remettre en mode train si besoin\n",
    "    model.train()\n",
    "    eval_time = time.time() - start_time\n",
    "\n",
    "# V√©rifier qu'on a des r√©sultats\n",
    "if len(pegasus_rouge1) == 0:\n",
    "    print(\"‚ùå Aucun exemple n'a pu √™tre √©valu√©\")\n",
    "    pegasus_rouge1 = [0]\n",
    "    pegasus_rouge2 = [0]\n",
    "    pegasus_rougeL = [0]\n",
    "    pegasus_rougeLsum = [0]\n",
    "\n",
    "# ==============================================\n",
    "# 9. R√âSULTATS ROUGE (comme l'article)\n",
    "# ==============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìà R√âSULTATS ROUGE - PEGASUS FINE-TUN√â\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "pegasus_r1 = np.mean(pegasus_rouge1) * 100\n",
    "pegasus_r2 = np.mean(pegasus_rouge2) * 100\n",
    "pegasus_rL = np.mean(pegasus_rougeL) * 100\n",
    "pegasus_rLsum = np.mean(pegasus_rougeLsum) * 100\n",
    "\n",
    "print(f\"\\nüéØ TES R√âSULTATS PEGASUS ({len(pegasus_rouge1)} exemples):\")\n",
    "print(f\"  ROUGE-1:    {pegasus_r1:.2f}%\")\n",
    "print(f\"  ROUGE-2:    {pegasus_r2:.2f}%\")\n",
    "print(f\"  ROUGE-L:    {pegasus_rL:.2f}%\")\n",
    "print(f\"  ROUGE-Lsum: {pegasus_rLsum:.2f}%\")\n",
    "\n",
    "print(f\"\\nüìä STATISTIQUES:\")\n",
    "print(f\"  √âcart-type ROUGE-1: {np.std(pegasus_rouge1)*100:.2f}%\")\n",
    "print(f\"  Temps d'√©valuation: {eval_time/60:.1f} min\")\n",
    "print(f\"  Exemples √©valu√©s: {len(pegasus_rouge1)}/1000\")\n",
    "\n",
    "# ==============================================\n",
    "# 10. COMPARAISON AVEC L'ARTICLE\n",
    "# ==============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä COMPARAISON AVEC L'ARTICLE (Table 3)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n{'Mod√®le':<25} {'ROUGE-1':<10} {'ROUGE-2':<10} {'ROUGE-L':<10} {'ROUGE-Lsum':<10}\")\n",
    "print(\"-\" * 65)\n",
    "print(f\"{'Article PEGASUS':<25} {33.69:<10.2f} {21.58:<10.2f} {28.43:<10.2f} {23.76:<10.2f}\")\n",
    "print(f\"{'Ton PEGASUS (5000 ex)':<25} {pegasus_r1:<10.2f} {pegasus_r2:<10.2f} {pegasus_rL:<10.2f} {pegasus_rLsum:<10.2f}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "difference_rouge1 = pegasus_r1 - 33.69\n",
    "print(f\"\\nüìà Diff√©rence ROUGE-1: {difference_rouge1:+.2f}%\")\n",
    "\n",
    "if difference_rouge1 > 0:\n",
    "    print(\"‚úÖ Ton mod√®le performe MIEUX que l'article !\")\n",
    "elif difference_rouge1 > -5:\n",
    "    print(\"üëç Performance proche de l'article (normal avec moins de donn√©es)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Performance inf√©rieure (normal: 5000 vs 287K exemples dans l'article)\")\n",
    "\n",
    "# ==============================================\n",
    "# 11. COMPARAISON AVEC LES AUTRES MOD√àLES (SI DISPONIBLE)\n",
    "# ==============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä COMPARAISON DES MOD√àLES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def load_previous_results(model_name):\n",
    "    \"\"\"Charge les r√©sultats pr√©c√©dents si disponibles\"\"\"\n",
    "    import json\n",
    "    path = f\"./{model_name}_finetuned_results/results.json\"\n",
    "    if os.path.exists(path):\n",
    "        try:\n",
    "            with open(path, 'r') as f:\n",
    "                return json.load(f)\n",
    "        except:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "gpt2_results = load_previous_results(\"gpt2\")\n",
    "bart_results = load_previous_results(\"bart\")\n",
    "\n",
    "print(f\"\\n{'Mod√®le':<15} {'ROUGE-1':<10} {'ROUGE-2':<10} {'Diff√©rence article':<20}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Afficher PEGASUS\n",
    "print(f\"{'PEGASUS':<15} {pegasus_r1:<10.2f} {pegasus_r2:<10.2f} {difference_rouge1:+.2f}%\")\n",
    "\n",
    "# Afficher BART si disponible\n",
    "if bart_results:\n",
    "    bart_r1 = bart_results[\"evaluation\"][\"rouge1\"]\n",
    "    bart_diff = bart_results[\"comparison_with_article\"][\"difference_rouge1\"]\n",
    "    print(f\"{'BART':<15} {bart_r1:<10.2f} {bart_results['evaluation']['rouge2']:<10.2f} {bart_diff:+.2f}%\")\n",
    "\n",
    "# Afficher GPT-2 si disponible\n",
    "if gpt2_results:\n",
    "    gpt2_r1 = gpt2_results[\"evaluation\"][\"rouge1\"]\n",
    "    gpt2_diff = gpt2_results[\"comparison_with_article\"][\"difference_rouge1\"]\n",
    "    print(f\"{'GPT-2':<15} {gpt2_r1:<10.2f} {gpt2_results['evaluation']['rouge2']:<10.2f} {gpt2_diff:+.2f}%\")\n",
    "\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Analyse comparative\n",
    "if gpt2_results and bart_results:\n",
    "    print(f\"\\nüìà CLASSEMENT DES MOD√àLES:\")\n",
    "\n",
    "    models = [\n",
    "        (\"PEGASUS\", pegasus_r1),\n",
    "        (\"BART\", bart_r1),\n",
    "        (\"GPT-2\", gpt2_r1)\n",
    "    ]\n",
    "\n",
    "    # Trier par ROUGE-1 d√©croissant\n",
    "    sorted_models = sorted(models, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for i, (name, score) in enumerate(sorted_models):\n",
    "        print(f\"  {i+1}. {name}: {score:.2f}% ROUGE-1\")\n",
    "\n",
    "    # V√©rifier l'ordre attendu\n",
    "    expected_order = [\"PEGASUS\", \"BART\", \"GPT-2\"]\n",
    "    actual_order = [name for name, _ in sorted_models]\n",
    "\n",
    "    if actual_order == expected_order:\n",
    "        print(f\"\\n‚úÖ Confirm√©: PEGASUS > BART > GPT-2 (comme l'article)\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  Ordre diff√©rent de l'article: {' > '.join(actual_order)}\")\n",
    "\n",
    "# ==============================================\n",
    "# 12. SAUVEGARDE DES R√âSULTATS\n",
    "# ==============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üíæ SAUVEGARDE DES R√âSULTATS PEGASUS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Cr√©er dossier r√©sultats\n",
    "results_dir = \"./pegasus_finetuned_results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Sauvegarder les r√©sultats\n",
    "results = {\n",
    "    \"model\": \"PEGASUS (175M) fine-tuned\",\n",
    "    \"training\": {\n",
    "        \"examples\": 5000,\n",
    "        \"validation\": 1000,\n",
    "        \"epochs\": 5,\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"batch_size\": training_args.per_device_train_batch_size,\n",
    "        \"gradient_accumulation\": training_args.gradient_accumulation_steps,\n",
    "        \"training_time_minutes\": train_result.metrics['train_runtime'] / 60 if 'train_result' in locals() else None\n",
    "    },\n",
    "    \"evaluation\": {\n",
    "        \"test_examples\": len(pegasus_rouge1),\n",
    "        \"rouge1\": float(pegasus_r1),\n",
    "        \"rouge2\": float(pegasus_r2),\n",
    "        \"rougeL\": float(pegasus_rL),\n",
    "        \"rougeLsum\": float(pegasus_rLsum),\n",
    "        \"std_rouge1\": float(np.std(pegasus_rouge1) * 100),\n",
    "        \"evaluation_time_minutes\": eval_time / 60\n",
    "    },\n",
    "    \"comparison_with_article\": {\n",
    "        \"article_rouge1\": 33.69,\n",
    "        \"article_rouge2\": 21.58,\n",
    "        \"article_rougeL\": 28.43,\n",
    "        \"article_rougeLsum\": 23.76,\n",
    "        \"difference_rouge1\": float(difference_rouge1)\n",
    "    },\n",
    "    \"date\": datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "with open(os.path.join(results_dir, \"results.json\"), \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ R√©sultats sauvegard√©s dans: {results_dir}/results.json\")\n",
    "\n",
    "# ==============================================\n",
    "# 13. T√âL√âCHARGEMENT (optionnel - pour Google Colab)\n",
    "# ==============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üì¶ PR√âPARATION DU T√âL√âCHARGEMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    import shutil\n",
    "\n",
    "    # Cr√©er ZIP avec mod√®le + r√©sultats\n",
    "    final_dir = \"./pegasus_project_final\"\n",
    "    os.makedirs(final_dir, exist_ok=True)\n",
    "\n",
    "    # Copier mod√®le\n",
    "    shutil.copytree(model_save_path, os.path.join(final_dir, \"model\"), dirs_exist_ok=True)\n",
    "    # Copier r√©sultats\n",
    "    shutil.copy(os.path.join(results_dir, \"results.json\"), os.path.join(final_dir, \"results.json\"))\n",
    "\n",
    "    # Cr√©er un rapport comparatif\n",
    "    if gpt2_results and bart_results:\n",
    "        comparative_report = f\"\"\"\n",
    "# RAPPORT COMPARATIF DES MOD√àLES\n",
    "\n",
    "## R√©sultats ROUGE-1:\n",
    "- PEGASUS: {pegasus_r1:.2f}% (Diff√©rence article: {difference_rouge1:+.2f}%)\n",
    "- BART:    {bart_r1:.2f}% (Diff√©rence article: {bart_diff:+.2f}%)\n",
    "- GPT-2:   {gpt2_r1:.2f}% (Diff√©rence article: {gpt2_diff:+.2f}%)\n",
    "\n",
    "## Classement:\n",
    "1. {sorted_models[0][0]}: {sorted_models[0][1]:.2f}%\n",
    "2. {sorted_models[1][0]}: {sorted_models[1][1]:.2f}%\n",
    "3. {sorted_models[2][0]}: {sorted_models[2][1]:.2f}%\n",
    "\n",
    "## Conclusion:\n",
    "Les r√©sultats confirment la hi√©rarchie g√©n√©rale PEGASUS > BART > GPT-2 pour la summarization,\n",
    "bien que les performances absolues soient inf√©rieures √† l'article d√ª √† l'entra√Ænement sur\n",
    "moins de donn√©es (5000 vs 287K exemples).\n",
    "\"\"\"\n",
    "\n",
    "        with open(os.path.join(final_dir, \"comparative_report.md\"), \"w\") as f:\n",
    "            f.write(comparative_report)\n",
    "\n",
    "    # Cr√©er ZIP\n",
    "    zip_name = \"pegasus_finetuned_project\"\n",
    "    shutil.make_archive(zip_name, 'zip', final_dir)\n",
    "\n",
    "    # T√©l√©charger (Google Colab)\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        files.download(f\"{zip_name}.zip\")\n",
    "        print(f\"‚úÖ Fichier t√©l√©charg√©: {zip_name}.zip\")\n",
    "    except:\n",
    "        print(f\"‚úÖ Fichier ZIP cr√©√©: {zip_name}.zip (non t√©l√©charg√© - pas en Colab)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Erreur lors de la cr√©ation du ZIP: {e}\")\n",
    "    print(\"Les r√©sultats sont quand m√™me sauvegard√©s dans le dossier.\")\n",
    "\n",
    "# ==============================================\n",
    "# 14. EXEMPLE DE R√âSULTAT\n",
    "# ==============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üîç EXEMPLE DE R√âSULTAT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Afficher un exemple de g√©n√©ration\n",
    "if len(pegasus_rouge1) > 0:\n",
    "    idx = 0  # Premier exemple\n",
    "    article = test_dataset[idx][\"article\"][:500] + \"...\"  # Truncate for display\n",
    "    reference = test_dataset[idx][\"highlights\"]\n",
    "\n",
    "    # G√©n√©rer un r√©sum√© pour cet exemple\n",
    "    model.eval()\n",
    "    generated = generate_summary_pegasus(test_dataset[idx][\"article\"], model, tokenizer, device)\n",
    "\n",
    "    print(f\"\\nüì∞ Article (tronqu√©):\")\n",
    "    print(article)\n",
    "    print(f\"\\nüìù R√©sum√© de r√©f√©rence:\")\n",
    "    print(reference)\n",
    "    print(f\"\\nü§ñ R√©sum√© g√©n√©r√©:\")\n",
    "    print(generated)\n",
    "\n",
    "    # Calculer les scores pour cet exemple\n",
    "    example_scores = scorer.score(reference, generated)\n",
    "    print(f\"\\nüìä Scores pour cet exemple:\")\n",
    "    print(f\"  ROUGE-1: {example_scores['rouge1'].fmeasure*100:.1f}%\")\n",
    "    print(f\"  ROUGE-2: {example_scores['rouge2'].fmeasure*100:.1f}%\")\n",
    "    print(f\"  ROUGE-L: {example_scores['rougeL'].fmeasure*100:.1f}%\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"‚úÖ PROJET PEGASUS TERMIN√â !\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"üìä R√©sum√© des r√©sultats:\")\n",
    "print(f\"  ‚Ä¢ ROUGE-1: {pegasus_r1:.2f}%\")\n",
    "print(f\"  ‚Ä¢ Diff√©rence avec l'article: {difference_rouge1:+.2f}%\")\n",
    "print(f\"  ‚Ä¢ Exemples √©valu√©s: {len(pegasus_rouge1)}/1000\")\n",
    "print(f\"  ‚Ä¢ Mod√®le sauvegard√©: {model_save_path}\")\n",
    "\n",
    "if gpt2_results and bart_results:\n",
    "    print(f\"\\nüéØ CLASSEMENT FINAL:\")\n",
    "    for i, (name, score) in enumerate(sorted_models):\n",
    "        print(f\"  {i+1}. {name}: {score:.2f}% ROUGE-1\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
